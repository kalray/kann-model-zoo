{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d745a2b7-8c8f-41ce-bc10-ef7dfbf0452a",
   "metadata": {},
   "source": [
    "# Quick start guide to generate and run YOLOv5 on MPPA with KANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a2a87-dc9f-47c1-b8b6-487353672433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quick start guide to generate and run YOLOv5s on MPPA with KANN\")\n",
    "print(\"> Going to upper directory (kann-models-zoo)\")\n",
    "%cd ..\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dc0ae-8f77-4fce-8ee7-55f71ec26e05",
   "metadata": {},
   "source": [
    "## GENERATE\n",
    "First step is to GENERATE an intermediate representation of your neural network to run on the MPPA. In this notebook, we propose you to generate a YOLOv5 from Texas Instrument ([link](https://github.com/TexasInstruments/edgeai-yolov5/blob/main/README.md)), already prepared for you in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a481419-d1ad-474e-a33f-4e3348767e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./generate networks/object-detection/yolov5s6-relu/onnx/network_f16.yaml -d yolov5s6 -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b027b-a89f-46fb-9198-de66dc7667a8",
   "metadata": {},
   "source": [
    "## RUN INFERENCE\n",
    "Once the model has been generated, you could use it with a prepared script and host application to run it on the MPPA. The script `run` would introduce you 2 modes:\n",
    "* `./run infer <model>` to evaluate the performance of the generated model on the MPPA\n",
    "* `./run demo  <model> <source>` to evaluate the neural network predictions and performance into a video/image pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497d45a-7531-41f1-9d06-360f4b6324b1",
   "metadata": {},
   "source": [
    "### Evaluate the neural network performance on the MPPA and HOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ab157-2483-4372-85e5-77c8ff4e9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./run infer yolov5s6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0a612-08c2-4b4f-87e8-d455443be518",
   "metadata": {},
   "source": [
    "Read the performance on the device (MPPA) and from the host application included in the KALRAY toolchain (kann_opencl_cnn). The host application in this case is not fully optimized, but give you a proper view of the runtime. Please contact our services at <support@kalrayinc.com> for more details to deploy your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9de50b-31ea-493a-9e38-e51a92c6b249",
   "metadata": {},
   "source": [
    "### Evaluate the neural network into a VIDEO pipeline\n",
    "\n",
    "The script will run several steps listed below. All timings are logged by the video demo script, and reported such as:\n",
    "+ read : time to import frame\n",
    "+ pre  : pre processing time\n",
    "+ send : copy data to FIFO in \n",
    "+ kann : wait until the FIFO out is filled (including the neural network inference)\n",
    "+ post : post processing time\n",
    "+ draw : draw annotation on input frame\n",
    "+ show : time to display the image though opencv\n",
    "+ total: sum of the previous timings\n",
    "\n",
    "To finalize the application, close the opencv window directly.\n",
    "\n",
    "NB: source can be an image, a set of image, a video or a webcam (use 0 if a device is already connected and properly installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28335e53-8bf4-4fba-add4-7dd1f102846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./run demo yolov5s6 ./utils/sources/cat.jpg --no-replay --save-img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46c413-7465-443e-99ba-26abb65d161a",
   "metadata": {},
   "source": [
    "display the image generated by the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832a693-ff91-4ddf-8ec0-213ac43b3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "display(Image.open(\"cat.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
