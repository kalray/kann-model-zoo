name: YOLOv8M-segmentation
framework: onnx
onnx_model: models/yolov8m-seg.optimized.onnx
onnx_graph_optim: true

input_nodes_name:
    - "images"
input_nodes_shape:
    - [640, 1, 640, 3]
input_nodes_dtype:
    - "float32"

output_nodes_name:
    - output1
    - /model.22/cv2.0/cv2.0.2/Conv_output_0
    - /model.22/cv2.1/cv2.1.2/Conv_output_0
    - /model.22/cv2.2/cv2.2.2/Conv_output_0
    - /model.22/cv3.0/cv3.0.2/Conv_output_0
    - /model.22/cv3.1/cv3.1.2/Conv_output_0
    - /model.22/cv3.2/cv3.2.2/Conv_output_0
    - /model.22/cv4.0/cv4.0.2/Conv_output_0
    - /model.22/cv4.1/cv4.1.2/Conv_output_0
    - /model.22/cv4.2/cv4.2.2/Conv_output_0
output_nodes_shape:
    - [160, 1, 160, 32]
    - [80, 1, 80, 64]
    - [40, 1, 40, 64]
    - [20, 1, 20, 64]
    - [ 80, 1, 80, 80 ]
    - [ 40, 1, 40, 80 ]
    - [ 20, 1, 20, 80 ]
    - [80, 1, 80, 32]
    - [40, 1, 40, 32]
    - [20, 1, 20, 32]
output_nodes_dtype:
    - "float32"
    - "float32"
    - "float32"
    - "float32"
    - "float32"
    - "float32"
    - "float32"
    - "float32"
    - "float32"
    - "float32"

generate_options:
    arch: "kv3-2"
    quantize_fp32_to_fp16: true
    data_buffer_size: 6240000
    code_buffer_size: 20000
    threshold_image_to_ddr: 10000000
    threshold_max_params_size: 500000
    ddr_images_tiles_size: 65535
    splitdepth_corrector_ratio: 256.0
    max_live_range: 20

extra_data:
    classes: classes.txt
    input_preparators:
        - input_preparator.py
    output_preparator: output_preparator
